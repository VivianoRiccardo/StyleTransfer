{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "StyleTransferCodice.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vJ3VuX4y1cW-",
        "e8KKANcHchv5",
        "nSCAYeXtyu6R",
        "lkt4a2ea-lke",
        "uVGQUuxa_IyB",
        "E_HK0RcgAPwt",
        "pH1dAx2RA56T"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_nWetWWd_ns"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6msVLevwcRhm"
      },
      "source": [
        "# Neural style transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8ajP_u73s6m"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84-29xmxosjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ceb3084-82d9-4193-a7e5-50ff0861a580"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "# Loada dei modelli compressi da tf\n",
        "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
        "\n",
        "import requests\n",
        "\n",
        "import IPython.display as display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools\n",
        " \n",
        "\n",
        "\n",
        "class Hyperparameters():\n",
        "  def __init__(self):\n",
        "    self.optimizer = 'ADAM'\n",
        "    self.lr = 0.001\n",
        "    self.momentum = 0.9\n",
        "    self.BETA1 = 0.9\n",
        "    self.BETA2 = 0.9\n",
        "    self.initial_accumulator_value = 0.01\n",
        "    self.epsilon = 1e-7\n",
        "    self.rho = 0.95\n",
        "    self.epochs = 100\n",
        "    self.steps_per_epoch = 100\n",
        "    self.style_weight = 100\n",
        "    self.content_weight = 1e-1\n",
        "    self.variational_weight = 0\n",
        "  def reset(self):\n",
        "    self.optimizer = 'ADAM'\n",
        "    self.lr = 0.001\n",
        "    self.momentum = 0.9\n",
        "    self.BETA1 = 0.9\n",
        "    self.BETA2 = 0.9\n",
        "    self.initial_accumulator_value = 0.01\n",
        "    self.epsilon = 1e-7\n",
        "    self.rho = 0.95\n",
        "    self.epochs = 100\n",
        "    self.steps_per_epoch = 100\n",
        "    self.style_weight = 100\n",
        "    self.content_weight = 1e-1\n",
        "    self.variational_weight = 0\n",
        "\n",
        "\n",
        "# classe con utils functions\n",
        "class Utils():\n",
        "\n",
        "  #trasforma un tensore in un oggetto immagine (Pil.Image)\n",
        "  def tensor_to_image(self,tensor):\n",
        "    tensor = tensor*255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor)>3:\n",
        "      assert tensor.shape[0] == 1\n",
        "      tensor = tensor[0]\n",
        "    return PIL.Image.fromarray(tensor)\n",
        "  # ritorna un oggetto immagine caricato da un path datogli, setta la massima dimensione a 512\n",
        "  def load_img(self,path_to_img):\n",
        "    max_dim = 512\n",
        "    img = tf.io.read_file(path_to_img)\n",
        "    img = tf.image.decode_image(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "    long_dim = max(shape)\n",
        "    scale = max_dim / long_dim\n",
        "\n",
        "    new_shape = tf.cast(shape * scale, tf.int32)\n",
        "\n",
        "    img = tf.image.resize(img, new_shape)\n",
        "    img = img[tf.newaxis, :]\n",
        "    return img\n",
        "  # printa a schermo l'immagine datagli\n",
        "  def imshow(self,image, title=None):\n",
        "    if len(image.shape) > 3:\n",
        "      image = tf.squeeze(image, axis=0)\n",
        "\n",
        "    \n",
        "    if title:\n",
        "      plt.title(title)\n",
        "  def clip_0_1(self,image):\n",
        "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ModelStructure(tf.keras.models.Model):\n",
        "  def __init__(self,util):\n",
        "    super(ModelStructure, self).__init__()\n",
        "    # questi parametri sono settati di default con l'inizializzazione del costruttore\n",
        "    # possono essere modificati duranti il training\n",
        "    self.util = util\n",
        "    url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "    response = requests.get(url)\n",
        "    file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "    file.write(response.content)\n",
        "    file.close()\n",
        "    self.content_path = \"Tuebingen_Neckarfront.jpg\"\n",
        "    self.style_path = tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')\n",
        "    self.training_image_path= \"Tuebingen_Neckarfront.jpg\"\n",
        "    self.vgg = None\n",
        "    self.vgg =  self.vgg_layers(['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1','block4_conv2','block5_conv1','block5_conv2'])\n",
        "    self.style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
        "    self.content_layers = ['block4_conv2']\n",
        "    self.num_style_layers = len(self.style_layers)\n",
        "    self.num_content_layers = len(self.content_layers)\n",
        "    self.opt = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
        "    self.content_image = tf.Variable(util.load_img(self.content_path))\n",
        "    self.style_image = tf.Variable(util.load_img(self.style_path))\n",
        "    self.image = self.content_image\n",
        "    self.style_weight=1e-2\n",
        "    self.content_weight=1e4\n",
        "    self.total_variation_weight=50\n",
        "    \n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"Expects float input in [0,1]\"\n",
        "    inputs = inputs*255.0\n",
        "    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
        "    outputs = self.vgg(preprocessed_input)\n",
        "    style_outputs, content_outputs = (outputs[:self.num_style_layers], \n",
        "                                      outputs[self.num_style_layers:])\n",
        "\n",
        "    style_outputs = [self.gram_matrix(style_output)\n",
        "                     for style_output in style_outputs]\n",
        "\n",
        "    content_dict = {content_name:value \n",
        "                    for content_name, value \n",
        "                    in zip(self.content_layers, content_outputs)}\n",
        "\n",
        "    style_dict = {style_name:value\n",
        "                  for style_name, value\n",
        "                  in zip(self.style_layers, style_outputs)}\n",
        "    \n",
        "    return {'content':content_dict, 'style':style_dict}\n",
        "  \n",
        "  def printVggLayers(self):\n",
        "    for layer in self.content_layers:\n",
        "      print(layer)\n",
        "    for layer1 in self.style_layers:\n",
        "      print(layer1)\n",
        "\n",
        "  def set_content_image(self,image_path):\n",
        "    self.content_path = image_path\n",
        "    self.content_image = tf.Variable(self.util.load_img(image_path))\n",
        "  def set_style_image(self,image_path):\n",
        "    self.style_path = image_path\n",
        "    self.style_image = tf.Variable(self.util.load_img(image_path))\n",
        "  def set_training_image(self,image_path):\n",
        "    self.training_image_path=image_path\n",
        "    #training_image_path=\"/content/gdrive/MyDrive/rumore_bianco.jpg\"\n",
        "    #img = tf.io.read_file(training_image_path)\n",
        "    self.image = tf.Variable(self.util.load_img(image_path))\n",
        "    \n",
        "    \n",
        "  #ritorna un modello rispetto agli output dati in layer names\n",
        "  def vgg_layers(self,layer_names):\n",
        "    self.vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet', pooling='avg')# carica vgg senza i fully connected layers finali (vgg usata per la classification)\n",
        "    self.vgg.trainable = False\n",
        "    outputs = [self.vgg.get_layer(name).output for name in layer_names]\n",
        "    model = tf.keras.Model([self.vgg.input], outputs)\n",
        "    return model\n",
        "  \n",
        "  def set_loss_weights(self,style_weight, content_weight, variation_weight):\n",
        "    self.style_weight = style_weight\n",
        "    self.content_weight = content_weight\n",
        "    self.total_variation_weight=variation_weight\n",
        "\n",
        "  def set_vgg_layers(self,style_layers, content_layers):\n",
        "    self.num_style_layers = len(style_layers)\n",
        "    self.num_content_layers = len(content_layers)\n",
        "    self.style_layers = style_layers\n",
        "    self.content_layers = content_layers\n",
        "    self.vgg = self.vgg_layers(style_layers+content_layers)\n",
        "  \n",
        "  def set_optimizer(self,optimizer,learning_rate,momentum,beta_1, beta_2, initial_accumulator_value, epsilon, rho):\n",
        "    if optimizer == 'ADAM':\n",
        "      self.opt = tf.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2 = beta_2, epsilon=epsilon)\n",
        "    elif optimizer == 'ADAGRAD': \n",
        "      self.opt = tf.keras.optimizers.Adagrad(learning_rate=learning_rate, initial_accumulator_value=initial_accumulator_value,epsilon=epsilon)\n",
        "    elif optimizer == 'RMSPROP':\n",
        "      self.opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate,rho=rho, momentum=momentum, epsilon=epsilon)\n",
        "    elif optimizer == 'ADADELTA':\n",
        "      self.opt = tf.keras.optimizers.Adadelta(learning_rate=learning_rate, rho=rho, epsilon=epsilon)\n",
        "    elif optimizer == 'ADAMAX':\n",
        "      self.opt = tf.keras.optimizers.Adamax(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
        "\n",
        "  # computa la gram matrix per lo style error\n",
        "  def gram_matrix(self,input_tensor):\n",
        "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
        "    input_shape = tf.shape(input_tensor)\n",
        "    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
        "    return result/(num_locations)\n",
        "  \n",
        "  def style_content_loss(self,outputs, style_targets, content_targets):\n",
        "    style_outputs = outputs['style']\n",
        "    content_outputs = outputs['content']\n",
        "    style_loss = tf.add_n([tf.reduce_mean(tf.square(style_outputs[name]-style_targets[name])) \n",
        "                           for name in style_outputs.keys()])\n",
        "    style_loss *= self.style_weight / self.num_style_layers\n",
        "\n",
        "    content_loss = tf.add_n([tf.reduce_mean(tf.square(content_outputs[name]-content_targets[name])) \n",
        "                             for name in content_outputs.keys()])\n",
        "    content_loss *= self.content_weight / self.num_content_layers\n",
        "    loss = style_loss + content_loss\n",
        "   \n",
        "    return loss \n",
        "  def reset(self):\n",
        "    url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "    response = requests.get(url)\n",
        "    file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "    file.write(response.content)\n",
        "    file.close()\n",
        "    self.content_path = \"Tuebingen_Neckarfront.jpg\"\n",
        "    self.style_path = tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')\n",
        "    self.training_image_path= \"Tuebingen_Neckarfront.jpg\"\n",
        "    self.vgg = None\n",
        "    self.vgg =  self.vgg_layers(['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1','block4_conv2','block5_conv1','block5_conv2'])\n",
        "    self.style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
        "    self.content_layers = ['block4_conv2']\n",
        "    self.num_style_layers = len(self.style_layers)\n",
        "    self.num_content_layers = len(self.content_layers)\n",
        "    self.opt = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
        "    self.content_image = tf.Variable(util.load_img(self.content_path))\n",
        "    self.style_image = tf.Variable(util.load_img(self.style_path))\n",
        "    self.image = self.content_image\n",
        "    self.style_weight=1e-2\n",
        "    self.content_weight=1e4\n",
        "    self.total_variation_weight=50\n",
        "@tf.function()\n",
        "def train_step(model,image, style, content):\n",
        "  with tf.GradientTape() as tape:\n",
        "    outputs = model(image)\n",
        "    loss = model.style_content_loss(outputs,style,content)\n",
        "    loss += model.total_variation_weight*tf.image.total_variation(image)\n",
        "    \n",
        "  grad = tape.gradient(loss, image)\n",
        "  model.opt.apply_gradients([(grad, image)])\n",
        "  image.assign(util.clip_0_1(image))\n",
        "  return loss\n",
        "\n",
        "\n",
        "\n",
        "def model_training_and_output(epochs, steps_per_epoch, model):\n",
        "  step = 0\n",
        "  image = tf.Variable(model.util.load_img(model.training_image_path))\n",
        "  model.set_content_image(model.content_path)\n",
        "  model.set_style_image(model.style_path)\n",
        "  style = model(model.style_image)['style']\n",
        "  content = model(model.content_image)['content']\n",
        "  losses=[]\n",
        "  step=0\n",
        "  for n in range(epochs):\n",
        "    for m in range(steps_per_epoch):\n",
        "      \n",
        "      \n",
        "      loss = train_step(model,image, style,content)\n",
        "      losses=np.append(losses, loss[0])\n",
        "      step += 1\n",
        "      print(\".\", end='')\n",
        "    #display.clear_output(wait=True)\n",
        "    print(loss)\n",
        "    display.display(model.util.tensor_to_image(image))\n",
        "    print(\"Train step: {}\".format(step))\n",
        "  lo1=losses[200:1499]  \n",
        "  plt.plot(lo1)\n",
        "  plt.title('TOTAL LOSS OVER FIRST 15 EPOCHS (without first 2)')\n",
        "  plt.savefig('losses1.png')\n",
        "  file_name1 = 'losses1.png'\n",
        "  files.download(file_name1)\n",
        "  plt.show() \n",
        "  lo2=losses[1500:]\n",
        "  plt.plot(lo2)\n",
        "  plt.title('TOTAL LOSS OVER EPOCHS > 15')\n",
        "  plt.show() \n",
        "  plt.savefig('losses2.png')\n",
        "  file_name2 = 'losses2.png'\n",
        "  files.download(file_name2)\n",
        "  return image\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTo99SocK23v"
      },
      "source": [
        "# MODEL INITIALIZATION AND HYPERPARAMETERS INITIALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62R3dyNXK5LJ"
      },
      "source": [
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        "param = Hyperparameters()\n",
        "\n",
        "param.reset()\n",
        "model.set_optimizer(param.optimizer,param.lr,param.momentum,param.BETA1,param.BETA2,param.initial_accumulator_value,param.epsilon,param.rho)\n",
        "model.set_loss_weights(param.style_weight,param.content_weight,param.variational_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or8V0GV2PYws"
      },
      "source": [
        "# WHITE NOISE IMAGE CREATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wABui5YdPcRm"
      },
      "source": [
        "training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TM3IPEc1lFz"
      },
      "source": [
        "# VARIE TRY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPCPKL-cyFQ8"
      },
      "source": [
        "# Relazione. Subsection 4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjI5ZyCPx4KA"
      },
      "source": [
        "# 4.1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEdXZHt_yOPb"
      },
      "source": [
        "model = ModelStructure(util)\n",
        "param.reset()\n",
        "model.set_optimizer(param.optimizer,param.lr,param.momentum,param.BETA1,param.BETA2,param.initial_accumulator_value,param.epsilon,param.rho)\n",
        "model.set_loss_weights(param.style_weight,param.content_weight,param.variational_weight)\n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'paper_fig2_minotaur.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O68v86fKqzDZ"
      },
      "source": [
        "\n",
        "#different content/style weight (1000) and total wariation weight=100\n",
        "model = ModelStructure(util)\n",
        "param.reset()\n",
        "model.set_optimizer(param.optimizer,param.lr,param.momentum,param.BETA1,param.BETA2,param.initial_accumulator_value,param.epsilon,param.rho)\n",
        "param.style_weight = 5e-3\n",
        "param.content_weight = 5000\n",
        "param.variational_weight = 50\n",
        "model.set_loss_weights(param.style_weight,param.content_weight,param.variational_weight)\n",
        "\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  url = 'https://www.artble.com/imgs/c/d/1/98090/the_shipwreck_of_the_minotaur.jpg'\n",
        "  response = requests.get(url)\n",
        "  file = open(\"the_shipwreck_of_the_minotaur.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "  model.set_style_image(\"the_shipwreck_of_the_minotaur.jpg\")\n",
        "  model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1', 'block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'paper_fig2_minotaur(fixed).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7O1Pe-PFbv6"
      },
      "source": [
        "# 4.1.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8X1VFNT9DMp"
      },
      "source": [
        "# 4.1.2\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.005\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 100\n",
        "  steps_per_epoch = 100\n",
        "  \n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 100\n",
        "  content_weight = 1e-1\n",
        "  variational_weight = 0\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  \n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1200px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"starry_night.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_style_image(\"starry_night.jpg\")\n",
        "  #model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  #c'è anche per il content image\n",
        "  #content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block4_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'paper_fig2_starry.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmIY5BP8vO9D"
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.001\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 30\n",
        "  steps_per_epoch = 100\n",
        "  \n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 1e-3\n",
        "  content_weight = 3000\n",
        "  variational_weight = 0\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  \n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1200px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"starry_night.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_style_image(\"starry_night.jpg\")\n",
        "  #model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  #c'è anche per il content image\n",
        "  #content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'paper_fig2_starry(fixed).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvfNHnxmG3_d"
      },
      "source": [
        "# 4.1.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16gtdf5o8-da"
      },
      "source": [
        "# 4.1.3\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.001\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 100\n",
        "  steps_per_epoch = 100\n",
        "  \n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 100\n",
        "  content_weight = 1e-1\n",
        "  variational_weight = 0\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  \n",
        "  url = 'https://www.theartpostblog.com/wp-content/uploads/2018/04/img-urlo-much.jpg'\n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"scream.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_style_image(\"scream.jpg\")\n",
        " \n",
        "  #c'è anche per il content image\n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block4_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'paper_fig2_scream.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn3el4qlLR4D"
      },
      "source": [
        "# 4.1.3 (our Parameters)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.005\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 100\n",
        "  steps_per_epoch = 100\n",
        "  \n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 1e-1\n",
        "  content_weight = 100\n",
        "  variational_weight = 500\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  \n",
        "  url = 'https://www.theartpostblog.com/wp-content/uploads/2018/04/img-urlo-much.jpg'\n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"scream.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_style_image(\"scream.jpg\")\n",
        "  #model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  #c'è anche per il content image\n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block4_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'paper_fig2_scream(fixed).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6UsC5TVLgmI"
      },
      "source": [
        "# 4.1.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibsswy0B_lKu"
      },
      "source": [
        "\n",
        "# 4.1.4\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.005\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 50\n",
        "  steps_per_epoch = 100\n",
        "  \n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 100\n",
        "  content_weight = 1e-2\n",
        "  variational_weight = 0\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  \n",
        "  url = 'https://az334033.vo.msecnd.net/images-7/seated-nude-femme-nue-assise-pablo-picasso-1909-f9095482.jpg'\n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"femme_nue.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_style_image(\"femme_nue.jpg\")\n",
        "  #model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  #c'è anche per il content image\n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block4_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'paper_fig2_femme.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Ig6c5pQxjV"
      },
      "source": [
        "# 4.1.4\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.005\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 30\n",
        "  steps_per_epoch = 100\n",
        "  \n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 1e-2\n",
        "  content_weight = 1000\n",
        "  variational_weight = 0\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  \n",
        "  url = 'https://az334033.vo.msecnd.net/images-7/seated-nude-femme-nue-assise-pablo-picasso-1909-f9095482.jpg'\n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"femme_nue.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_style_image(\"femme_nue.jpg\")\n",
        "  #model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  #c'è anche per il content image\n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'paper_fig2_femme(fixed).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaF26BFwRq9P"
      },
      "source": [
        "# 4.1.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WxSdcy-IAeSk"
      },
      "source": [
        "\n",
        "# 4.1.5\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.005\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 50\n",
        "  steps_per_epoch = 100\n",
        "  \n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 100\n",
        "  content_weight = 1e-2\n",
        "  variational_weight = 0\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  \n",
        "  \n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  #c'è anche per il content image\n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block4_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig2_kandinsky.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzA3cbUljJX1"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# 4.1.5\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.005\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 60\n",
        "  steps_per_epoch = 100\n",
        "  \n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 1e-1\n",
        "  content_weight = 5000\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  \n",
        "  \n",
        "\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  #c'è anche per il content image\n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig2_kandinsky(fixed).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeXL5dslyURN"
      },
      "source": [
        "# Relazione. Subsection 4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGYKvJEy_Mi"
      },
      "source": [
        "# 4.2.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stGYGUWwy2JT"
      },
      "source": [
        "# 4.2.1\n",
        "\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.005\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 30\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-3\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini  \n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  #c'è anche per il content image\n",
        "\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(1,1).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZc4P4jLYIdV"
      },
      "source": [
        "# 4.2.2\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.005\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 20\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-2\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(1,2).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kVnJMxDYrYa"
      },
      "source": [
        "# 4.2.3\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.005\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 20\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-1\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(1,3).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jy1iK3RZdda"
      },
      "source": [
        "# 4.2.4\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.005\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 20\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 10000\n",
        "content_weight = 100\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(1,4).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3deYB3BiMR7"
      },
      "source": [
        "# 4.2.2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcRSXwfSZy10"
      },
      "source": [
        "# 4.2.5\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.005\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 20\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-3\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(2,1).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaaBrE1_V8uT"
      },
      "source": [
        "# 4.2.6\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 10\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-2\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(content_weight/style_weight)\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block1_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(2,2).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4bY2hHtY2V-"
      },
      "source": [
        "# 4.2.7\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-1\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(2,3).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt4eh9HiZsqn"
      },
      "source": [
        "# 4.2.8\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 30\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 1000\n",
        "content_weight = 10\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(content_weight / style_weight)\n",
        "\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block1_conv1']\n",
        "style_layers = ['block1_conv1', 'block2_conv2']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(2,4).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFqb-73_aet_"
      },
      "source": [
        "# 4.2.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LcWqYnpaiXu"
      },
      "source": [
        "# 4.2.9\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-3\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(3,1).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hmPZDrLbKWc"
      },
      "source": [
        "# 4.2.10\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-2\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(3,2).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n-ewO9pbRsu"
      },
      "source": [
        "# 4.2.11\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-1\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(3,3).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqmBh4cAbZs_"
      },
      "source": [
        "# 4.2.12\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-1\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(3,4).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8KKANcHchv5"
      },
      "source": [
        "# 4.2.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaNaHAoKclqS"
      },
      "source": [
        "# 4.2.13\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-3\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1', 'block4_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(4,1).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqWfVKTLc3Wy"
      },
      "source": [
        "# 4.2.14\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-2\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1', 'block4_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(4,2).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJGXxgdMc-tk"
      },
      "source": [
        "# 4.2.15\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-1\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1', 'block4_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(4,3).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjnYi8P_dFkS"
      },
      "source": [
        "# 4.2.16\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 1000\n",
        "content_weight = 10\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1', 'block4_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(4,4).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdP4N94DdL-l"
      },
      "source": [
        "# 4.2.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5sq4ZSpdXMu"
      },
      "source": [
        "# 4.2.17\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-3\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(5,1).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpovsZJ7dhrP"
      },
      "source": [
        "# 4.2.18\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-2\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(5,2).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kZyVIPkdm32"
      },
      "source": [
        "# 4.2.19\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 100\n",
        "content_weight = 1e-1\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(5,3).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2f0G4tjdrz1"
      },
      "source": [
        "# 4.2.20\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util)\n",
        " \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.9\n",
        "initial_accumulator_value = 0.01\n",
        "epsilon = 1e-7\n",
        "rho = 0.95\n",
        "epochs = 150\n",
        "steps_per_epoch = 100\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  \n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 1000\n",
        "content_weight = 10\n",
        "print(\"alpha - beta ratio: \")\n",
        "print(int(content_weight / style_weight))\n",
        "variational_weight = 0\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv2', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = 'paper_fig3(5,4).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p_eFB5AI8gv"
      },
      "source": [
        "# Customized training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJs4CggMJDKn"
      },
      "source": [
        "# Content Image = Training Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJwmgP8mJKTg"
      },
      "source": [
        "# 4.3.1\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util) \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM' #@param[\"ADAM\", \"ADAMAX\" , \"ADAGRAD\", \"ADADELTA\", \"ADAGRAD\", \"SGD\", \"RMSPROP\"]\n",
        "lr = 0.005 #@param {type:\"number\"}\n",
        "momentum = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "BETA1 = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "BETA2 = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "initial_accumulator_value = 0.01 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "epsilon = 1e-7 \n",
        "rho = 0.95 \n",
        "epochs = 10 #@param {type:\"number\"}\n",
        "steps_per_epoch = 20 #@param {type:\"slider\", min:10, max:1000, step:10}\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 1e3 #@param {type:\"number\"}\n",
        "content_weight = 1e-4 #@param {type:\"number\"}\n",
        "variational_weight = 100 #@param {type:\"number\"}\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "style_url = 'https://az334033.vo.msecnd.net/images-7/seated-nude-femme-nue-assise-pablo-picasso-1909-f9095482.jpg' #@param {type:\"raw\"}\n",
        "response = requests.get(style_url)\n",
        "file = open(\"femme_nue.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()\n",
        "model.set_style_image(\"femme_nue.jpg\")\n",
        "#c'è anche per il content image\n",
        "content_url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg' #@param {type:\"raw\"}\n",
        "response = requests.get(content_url)\n",
        "file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "\n",
        "  #training image\n",
        "model.set_training_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block5_conv2'] #@param {type:\"raw\"}\n",
        "style_layers = ['block2_conv1', 'block3_conv1'] #@param {type:\"raw\"}\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  #training procedure\n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'Tuebigen_Femme.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R113AVr_N8a2"
      },
      "source": [
        "# Max vs Average Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DGbZ0vFcN9x8"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "# Loada dei modelli compressi da tf\n",
        "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
        "\n",
        "import requests\n",
        "\n",
        "import IPython.display as display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# classe con utils functions\n",
        "class Utils():\n",
        "\n",
        "  #trasforma un tensore in un oggetto immagine (Pil.Image)\n",
        "  def tensor_to_image(self,tensor):\n",
        "    tensor = tensor*255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor)>3:\n",
        "      assert tensor.shape[0] == 1\n",
        "      tensor = tensor[0]\n",
        "    return PIL.Image.fromarray(tensor)\n",
        "  # ritorna un oggetto immagine caricato da un path datogli, setta la massima dimensione a 512\n",
        "  def load_img(self,path_to_img):\n",
        "    max_dim = 512\n",
        "    img = tf.io.read_file(path_to_img)\n",
        "    img = tf.image.decode_image(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "    long_dim = max(shape)\n",
        "    scale = max_dim / long_dim\n",
        "\n",
        "    new_shape = tf.cast(shape * scale, tf.int32)\n",
        "\n",
        "    img = tf.image.resize(img, new_shape)\n",
        "    img = img[tf.newaxis, :]\n",
        "    return img\n",
        "  # printa a schermo l'immagine datagli\n",
        "  def imshow(self,image, title=None):\n",
        "    if len(image.shape) > 3:\n",
        "      image = tf.squeeze(image, axis=0)\n",
        "\n",
        "    \n",
        "    if title:\n",
        "      plt.title(title)\n",
        "  def clip_0_1(self,image):\n",
        "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ModelStructure(tf.keras.models.Model):\n",
        "  def __init__(self,util):\n",
        "    super(ModelStructure, self).__init__()\n",
        "    # questi parametri sono settati di default con l'inizializzazione del costruttore\n",
        "    # possono essere modificati duranti il training\n",
        "    self.util = util\n",
        "    url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "    response = requests.get(url)\n",
        "    file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "    file.write(response.content)\n",
        "    file.close()\n",
        "    self.content_path = \"Tuebingen_Neckarfront.jpg\"\n",
        "    self.style_path = tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')\n",
        "    self.training_image_path= \"Tuebingen_Neckarfront.jpg\"\n",
        "    self.vgg = None\n",
        "    self.pool = 'avg'\n",
        "    self.vgg =  self.vgg_layers(['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1','block4_conv2','block5_conv1','block5_conv2'], self.pool)\n",
        "    self.style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
        "    self.content_layers = ['block4_conv2']\n",
        "    self.num_style_layers = len(self.style_layers)\n",
        "    self.num_content_layers = len(self.content_layers)\n",
        "    self.opt = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
        "    self.content_image = tf.Variable(util.load_img(self.content_path))\n",
        "    self.style_image = tf.Variable(util.load_img(self.style_path))\n",
        "    self.image = self.content_image\n",
        "    self.style_weight=1e-2\n",
        "    self.content_weight=1e4\n",
        "    self.total_variation_weight=50\n",
        "    \n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"Expects float input in [0,1]\"\n",
        "    inputs = inputs*255.0\n",
        "    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
        "    outputs = self.vgg(preprocessed_input)\n",
        "    style_outputs, content_outputs = (outputs[:self.num_style_layers], \n",
        "                                      outputs[self.num_style_layers:])\n",
        "\n",
        "    style_outputs = [self.gram_matrix(style_output)\n",
        "                     for style_output in style_outputs]\n",
        "\n",
        "    content_dict = {content_name:value \n",
        "                    for content_name, value \n",
        "                    in zip(self.content_layers, content_outputs)}\n",
        "\n",
        "    style_dict = {style_name:value\n",
        "                  for style_name, value\n",
        "                  in zip(self.style_layers, style_outputs)}\n",
        "    \n",
        "    return {'content':content_dict, 'style':style_dict}\n",
        "  \n",
        "  def printVggLayers(self):\n",
        "    for layer in self.content_layers:\n",
        "      print(layer)\n",
        "    for layer1 in self.style_layers:\n",
        "      print(layer1)\n",
        "\n",
        "  def set_content_image(self,image_path):\n",
        "    self.content_path = image_path\n",
        "    self.content_image = tf.Variable(self.util.load_img(image_path))\n",
        "  def set_style_image(self,image_path):\n",
        "    self.style_path = image_path\n",
        "    self.style_image = tf.Variable(self.util.load_img(image_path))\n",
        "  def set_training_image(self,image_path):\n",
        "    self.training_image_path=image_path\n",
        "    #training_image_path=\"/content/gdrive/MyDrive/rumore_bianco.jpg\"\n",
        "    #img = tf.io.read_file(training_image_path)\n",
        "    self.image = tf.Variable(self.util.load_img(image_path))\n",
        "    \n",
        "    \n",
        "  #ritorna un modello rispetto agli output dati in layer names\n",
        "  def vgg_layers(self,layer_names, pool):\n",
        "    if pool=='max':\n",
        "      self.vgg =  tf.keras.applications.VGG19(include_top=False, weights='imagenet') #max pooling is default in vgg19\n",
        "    elif pool=='avg':\n",
        "      self.vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet', pooling= pool)# carica vgg senza i fully connected layers finali (vgg usata per la classification)\n",
        "    self.vgg.trainable = False\n",
        "    outputs = [self.vgg.get_layer(name).output for name in layer_names]\n",
        "    model = tf.keras.Model([self.vgg.input], outputs)\n",
        "    return model\n",
        "  \n",
        "  def set_loss_weights(self,style_weight, content_weight, variation_weight):\n",
        "    self.style_weight = style_weight\n",
        "    self.content_weight = content_weight\n",
        "    self.total_variation_weight=variation_weight\n",
        "\n",
        "  def set_vgg_layers(self,style_layers, content_layers, pool):\n",
        "    self.num_style_layers = len(style_layers)\n",
        "    self.num_content_layers = len(content_layers)\n",
        "    self.style_layers = style_layers\n",
        "    self.content_layers = content_layers\n",
        "    self.vgg = self.vgg_layers(style_layers+content_layers, pool)\n",
        "  \n",
        "  def set_optimizer(self,optimizer,learning_rate,momentum,beta_1, beta_2, initial_accumulator_value, epsilon, rho):\n",
        "    if optimizer == 'ADAM':\n",
        "      self.opt = tf.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2 = beta_2, epsilon=epsilon)\n",
        "    elif optimizer == 'ADAGRAD': \n",
        "      self.opt = tf.keras.optimizers.Adagrad(learning_rate=learning_rate, initial_accumulator_value=initial_accumulator_value,epsilon=epsilon)\n",
        "    elif optimizer == 'RMSPROP':\n",
        "      self.opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate,rho=rho, momentum=momentum, epsilon=epsilon)\n",
        "    elif optimizer == 'ADADELTA':\n",
        "      self.opt = tf.keras.optimizers.Adadelta(learning_rate=learning_rate, rho=rho, epsilon=epsilon)\n",
        "    elif optimizer == 'ADAMAX':\n",
        "      self.opt = tf.keras.optimizers.Adamax(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
        "\n",
        "  # computa la gram matrix per lo style error\n",
        "  def gram_matrix(self,input_tensor):\n",
        "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
        "    input_shape = tf.shape(input_tensor)\n",
        "    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
        "    return result/(num_locations)\n",
        "  \n",
        "  def style_content_loss(self,outputs, style_targets, content_targets):\n",
        "    style_outputs = outputs['style']\n",
        "    content_outputs = outputs['content']\n",
        "    style_loss = tf.add_n([tf.reduce_mean(tf.square(style_outputs[name]-style_targets[name])) \n",
        "                           for name in style_outputs.keys()])\n",
        "    style_loss *= self.style_weight / self.num_style_layers\n",
        "\n",
        "    content_loss = tf.add_n([tf.reduce_mean(tf.square(content_outputs[name]-content_targets[name])) \n",
        "                             for name in content_outputs.keys()])\n",
        "    content_loss *= self.content_weight / self.num_content_layers\n",
        "    loss = style_loss + content_loss\n",
        "   \n",
        "    return loss \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@tf.function()\n",
        "def train_step(model,image, style, content):\n",
        "  with tf.GradientTape() as tape:\n",
        "    outputs = model(image)\n",
        "    loss = model.style_content_loss(outputs,style,content)\n",
        "    loss += model.total_variation_weight*tf.image.total_variation(image)\n",
        "    \n",
        "  grad = tape.gradient(loss, image)\n",
        "  model.opt.apply_gradients([(grad, image)])\n",
        "  image.assign(util.clip_0_1(image))\n",
        "  return loss\n",
        "\n",
        "\n",
        "\n",
        "def model_training_and_output(epochs, steps_per_epoch, model):\n",
        "  step = 0\n",
        "  image = tf.Variable(model.util.load_img(model.training_image_path))\n",
        "  model.set_content_image(model.content_path)\n",
        "  model.set_style_image(model.style_path)\n",
        "  style = model(model.style_image)['style']\n",
        "  content = model(model.content_image)['content']\n",
        "  losses=[]\n",
        "  step=0\n",
        "  for n in range(epochs):\n",
        "    for m in range(steps_per_epoch):\n",
        "      \n",
        "      \n",
        "      loss = train_step(model,image, style,content)\n",
        "      losses=np.append(losses, loss[0])\n",
        "      step += 1\n",
        "      print(\".\", end='')\n",
        "    #display.clear_output(wait=True)\n",
        "    print(loss)\n",
        "    display.display(model.util.tensor_to_image(image))\n",
        "    print(\"Train step: {}\".format(step))\n",
        "  lo1=losses[200:1499]  \n",
        "  plt.plot(lo1)\n",
        "  plt.title('TOTAL LOSS OVER FIRST 15 EPOCHS (without first 2)')\n",
        "  plt.savefig('losses1.png')\n",
        "  file_name1 = 'losses1.png'\n",
        "  files.download(file_name1)\n",
        "  plt.show() \n",
        "  lo2=losses[1500:]\n",
        "  plt.plot(lo2)\n",
        "  plt.title('TOTAL LOSS OVER EPOCHS > 15')\n",
        "  plt.show() \n",
        "  plt.savefig('losses2.png')\n",
        "  file_name2 = 'losses2.png'\n",
        "  files.download(file_name2)\n",
        "  return image\n",
        "\n",
        "\n",
        "\n",
        "####FINE SETUP\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 4.3.1\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util) \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM' #@param[\"ADAM\", \"ADAMAX\" , \"ADAGRAD\", \"ADADELTA\", \"ADAGRAD\", \"SGD\", \"RMSPROP\"]\n",
        "lr = 0.005 #@param {type:\"number\"}\n",
        "momentum = 0.29 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "BETA1 = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "BETA2 = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "initial_accumulator_value = 0.01 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "epsilon = 1e-7 \n",
        "rho = 0.95 \n",
        "epochs = 50 #@param {type:\"number\"}\n",
        "steps_per_epoch = 100 #@param {type:\"slider\", min:10, max:1000, step:10}\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 1e-2 #@param {type:\"number\"}\n",
        "content_weight = 1000 #@param {type:\"number\"}\n",
        "variational_weight = 0 #@param {type:\"number\"}\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "style_url = 'https://az334033.vo.msecnd.net/images-7/seated-nude-femme-nue-assise-pablo-picasso-1909-f9095482.jpg' #@param {type:\"raw\"}\n",
        "response = requests.get(style_url)\n",
        "file = open(\"femme_nue.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()\n",
        "model.set_style_image(\"femme_nue.jpg\")\n",
        "  #c'è anche per il content image\n",
        "content_url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg' #@param {type:\"raw\"}\n",
        "response = requests.get(content_url)\n",
        "file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  #training image\n",
        "training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block5_conv2'] #@param {type:\"raw\"}\n",
        "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1'] #@param {type:\"raw\"}\n",
        "pooling='avg' #@param[\"avg\" , \"max\"]\n",
        "model.set_vgg_layers(style_layers, content_layers, pooling)\n",
        "  \n",
        "  #training procedure\n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = '4.3(AVG).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rumNGMZkP-9_"
      },
      "source": [
        "# Different Content Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6CJR6U5P9dL"
      },
      "source": [
        "# 4.3.1\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util) \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM' #@param[\"ADAM\", \"ADAMAX\" , \"ADAGRAD\", \"ADADELTA\", \"ADAGRAD\", \"SGD\", \"RMSPROP\"]\n",
        "lr = 0.005 #@param {type:\"number\"}\n",
        "momentum = 0.29 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "BETA1 = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "BETA2 = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "initial_accumulator_value = 0.01 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "epsilon = 1e-7 \n",
        "rho = 0.95 \n",
        "epochs = 30 #@param {type:\"number\"}\n",
        "steps_per_epoch = 100 #@param {type:\"slider\", min:10, max:1000, step:10}\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 1e-2 #@param {type:\"number\"}\n",
        "content_weight = 1000 #@param {type:\"number\"}\n",
        "variational_weight = 0 #@param {type:\"number\"}\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "style_url = 'https://az334033.vo.msecnd.net/images-7/seated-nude-femme-nue-assise-pablo-picasso-1909-f9095482.jpg' #@param {type:\"raw\"}\n",
        "response = requests.get(style_url)\n",
        "file = open(\"femme_nue.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()\n",
        "model.set_style_image(\"femme_nue.jpg\")\n",
        "  #c'è anche per il content image\n",
        "content_url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg' #@param {type:\"raw\"}\n",
        "response = requests.get(content_url)\n",
        "file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  #training image\n",
        "training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block4_conv2', 'block5_conv2'] #@param {type:\"raw\"}\n",
        "#content_layers = ['block3_conv2', 'block4_conv2', 'block5_conv2']\n",
        "#content_layers = ['block3_conv2']\n",
        "#content_layers = ['block1_conv2']\n",
        "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1'] #@param {type:\"raw\"}\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  #training procedure\n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'Tuebigen_Femme.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRNFX9NLQFIR"
      },
      "source": [
        "# Different Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1Lqi1KgQTZY"
      },
      "source": [
        "# 4.3.1\n",
        "util = Utils()\n",
        "model = ModelStructure(util) \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAMAX' #@param[\"ADAM\", \"ADAMAX\", \"ADADELTA\", \"ADAGRAD\", \"SGD\", \"RMSPROP\"]\n",
        "#optimizer = 'ADAGRAD'\n",
        "#optimizer = 'ADADELTA'  \n",
        "#optimizer = 'ADAGRAD' \n",
        "#optimizer = 'RMSPROP' \n",
        "#optimizer = 'SGD'\n",
        "lr = 0.005 #@param {type:\"number\"}\n",
        "momentum = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "BETA1 = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "BETA2 = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "initial_accumulator_value = 0.01 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "epsilon = 1e-7 \n",
        "rho = 0.95 \n",
        "epochs = 30 #@param {type:\"number\"}\n",
        "steps_per_epoch = 100 #@param {type:\"slider\", min:10, max:1000, step:10}\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 1e-2 #@param {type:\"number\"}\n",
        "content_weight = 1000 #@param {type:\"number\"}\n",
        "variational_weight = 0 #@param {type:\"number\"}\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "style_url = 'https://az334033.vo.msecnd.net/images-7/seated-nude-femme-nue-assise-pablo-picasso-1909-f9095482.jpg' #@param {type:\"raw\"}\n",
        "response = requests.get(style_url)\n",
        "file = open(\"femme_nue.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()\n",
        "model.set_style_image(\"femme_nue.jpg\")\n",
        "  #c'è anche per il content image\n",
        "content_url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg' #@param {type:\"raw\"}\n",
        "response = requests.get(content_url)\n",
        "file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  #training image\n",
        "training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block5_conv2'] #@param {type:\"raw\"}\n",
        "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1'] #@param {type:\"raw\"}\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  #training procedure\n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'Tuebigen_Femme.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoU0FkDgQRdv"
      },
      "source": [
        "# Different momentum, betas, accumulator..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joXG4y5oQjsH"
      },
      "source": [
        "# 4.3.1\n",
        "\n",
        "util = Utils()\n",
        "model = ModelStructure(util) \n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "optimizer = 'ADAM' #@param[\"ADAM\", \"ADAMAX\" , \"ADAGRAD\", \"ADADELTA\", \"ADAGRAD\", \"SGD\", \"RMSPROP\"]\n",
        "lr = 0.005 #@param {type:\"number\"}\n",
        "momentum = 0.29 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "BETA1 = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "BETA2 = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "initial_accumulator_value = 0.01 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "epsilon = 1e-7 \n",
        "rho = 0.95 \n",
        "epochs = 30 #@param {type:\"number\"}\n",
        "steps_per_epoch = 100 #@param {type:\"slider\", min:10, max:1000, step:10}\n",
        "  \n",
        "model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "style_weight = 1e-2 #@param {type:\"number\"}\n",
        "content_weight = 1000 #@param {type:\"number\"}\n",
        "variational_weight = 0 #@param {type:\"number\"}\n",
        "model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "style_url = 'https://az334033.vo.msecnd.net/images-7/seated-nude-femme-nue-assise-pablo-picasso-1909-f9095482.jpg' #@param {type:\"raw\"}\n",
        "response = requests.get(style_url)\n",
        "file = open(\"femme_nue.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()\n",
        "model.set_style_image(\"femme_nue.jpg\")\n",
        "  #c'è anche per il content image\n",
        "content_url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg' #@param {type:\"raw\"}\n",
        "response = requests.get(content_url)\n",
        "file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()\n",
        "model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  #training image\n",
        "training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "training_image_path=\"noise.jpg\"\n",
        "model.set_training_image(training_image_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "content_layers = ['block5_conv2'] #@param {type:\"raw\"}\n",
        "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1'] #@param {type:\"raw\"}\n",
        "model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  #training procedure\n",
        "image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'Tuebigen_Femme.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJalb_ppftux"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 10 \n",
        "  content_weight = 10\n",
        "  variational_weight = 10\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  #c'è anche per il content image\n",
        "\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = '(10,10,10), ADAM(lr=0.01), style all 5, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn-ZmcF7f6Q7"
      },
      "source": [
        "# same parameters of the paper\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  \n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 0\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  #c'è anche per il content image\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block4_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "  \n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.01), style all 5, block4_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qQYFjnzgDNo"
      },
      "source": [
        "# learning rate greather (0.1)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAGRAD'\n",
        "  lr = 0.1\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.1\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        " \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.1), style all 5, block_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSrIbkRSgCyl"
      },
      "source": [
        "# learning rate lower (0.001)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.001\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        " \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.001), style all 5, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHvzT2-fghnF"
      },
      "source": [
        "# content/style weight 10^(-4)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 20000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = '(20000,2,50), ADAM (lr=0.01), style all 5, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os5hZvZfgtJ8"
      },
      "source": [
        "# content/style weight 10^(-3)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAGRAD'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 2000\n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "\n",
        "  image= model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "file_name = '(2000,2,50), ADAM (lr=0.01), style all 5, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfJi4hOMgxS0"
      },
      "source": [
        "# content/style weight 10^(-2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAGRAD'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200\n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "\n",
        "  image= model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = '(200,2,50), ADAM (lr=0.01), style all 5, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cjT2hcog12w"
      },
      "source": [
        "# content/style weight 10^(-1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 20\n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "\n",
        "file_name = '(20,2,50), ADAM (lr=0.01), style all 5, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxbRPIHghvaz"
      },
      "source": [
        "# content/style weight 100\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAGRAD'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 2\n",
        "  content_weight = 200\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = '(2,200,50), ADAM (lr=0.01), style all 5, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVK9ATVChY1a"
      },
      "source": [
        "#  DIFFERENT TOTAL VARIATION WEIGHT (1000)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAGRAD'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 1000\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  image=model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "\n",
        "file_name = '(200000,2,1000), ADAM (lr=0.01), style all 5, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic-PdOOm0Npj"
      },
      "source": [
        "#  DIFFERENT TOTAL VARIATION WEIGHT (10^(-1))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAGRAD'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 0.1\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "  \n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  image=model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "\n",
        "file_name = '(200000,2,0.1), ADAM (lr=0.01), style all 5, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08B40i7c0qbi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h67AoUyjnmjV"
      },
      "source": [
        "#DIFFERENT STYLE LAYERS (FIRST 3)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "  image= model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.01), style first 3, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVAa5Ze2omfB"
      },
      "source": [
        "#DIFFERENT STYLE LAYERS (FIRST 2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "  image= model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.01), style first 2, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v9bCrGBqgl8"
      },
      "source": [
        "#DIFFERENT STYLE LAYERS (FIRST ONLY)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "  image= model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.01), style first only, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huqJWdXLrx_p"
      },
      "source": [
        "#DIFFERENT STYLE LAYERS (LAST ONLY)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "  image= model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.01), style LAST only, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7bLqVZRasW3C"
      },
      "source": [
        "#DIFFERENT STYLE LAYERS (LAST 2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 10\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block4_conv1','block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "  image= model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.01), style LAST 2, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_HK0RcgAPwt"
      },
      "source": [
        "# DIFFERENT OPTIMIZERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjw9qe3tATSV"
      },
      "source": [
        "# RMSPROP\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'RMSPROP'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 30\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.01), style all 5, block5_2, epoch10(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TxMlRmgAkdT"
      },
      "source": [
        "# ADADELTA\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADADELTA'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 30\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.01), style all 5, block5_2, epoch40(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ownGJHCfAu8i"
      },
      "source": [
        "# ADAMAX\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAMAX'\n",
        "  lr = 0.01\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 30\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 200000 \n",
        "  content_weight = 2\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  model.set_style_image(tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg'))\n",
        "  content_path = \"/content/gdrive/MyDrive/immagine_paper.jpg\"\n",
        "  model.set_content_image(content_path)\n",
        "  model.set_training_image(content_path)\n",
        "\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block5_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = '(200000,2,50), ADAM (lr=0.01), style all 5, block5_2, epoch40(x100).png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH1dAx2RA56T"
      },
      "source": [
        "# WITH WHITE NOISE IMAGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xHYy-kfAA2M8"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        " \n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.005\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 40\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        " \n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 1e-1\n",
        "  content_weight = 100\n",
        "  variational_weight = 100\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        " \n",
        " \n",
        "  # posso cambiare le immagini\n",
        "  \n",
        "  url = 'https://www.artble.com/imgs/c/d/1/98090/the_shipwreck_of_the_minotaur.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        " \n",
        "  file = open(\"the_shipwreck_of_the_minotaur.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        " \n",
        "  model.set_style_image(\"the_shipwreck_of_the_minotaur.jpg\")\n",
        " \n",
        " \n",
        "  #c'è anche per il content image\n",
        "  \n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "  response = requests.get(url)\n",
        "  file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        " \n",
        "  model.set_content_image(\"saverio.jpg\")\n",
        "  \n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  \n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  \n",
        " \n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "  #model.set_training_image(tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'))\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block4_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        " \n",
        " \n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        " \n",
        " \n",
        "file_name = 'paper_fig2_minotaur.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        " \n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UilpLJ75a3Gf"
      },
      "source": [
        "#different content/style weight (1000) and total wariation weight=50\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  util = Utils()\n",
        "  model = ModelStructure(util)\n",
        "  #model_training_and_output(10,100,model)\n",
        "\n",
        "  # cambio dei settaggi, solo per l'optimizer e i relativi parametri associati\n",
        "  optimizer = 'ADAM'\n",
        "  lr = 0.03\n",
        "  momentum = 0.9\n",
        "  BETA1 = 0.9\n",
        "  BETA2 = 0.9\n",
        "  initial_accumulator_value = 0.01\n",
        "  epsilon = 1e-7\n",
        "  rho = 0.95\n",
        "  epochs = 12\n",
        "  steps_per_epoch = 100\n",
        "  model.set_optimizer(optimizer,lr,momentum,BETA1,BETA2,initial_accumulator_value,epsilon,rho)\n",
        "  #model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "  # per cambiare i pesi delle loss posso fare\n",
        "  style_weight = 1e-1\n",
        "  content_weight = 100\n",
        "  variational_weight = 50\n",
        "  model.set_loss_weights(style_weight,content_weight,variational_weight)\n",
        "\n",
        "\n",
        "  # posso cambiare le immagini\n",
        "  \n",
        "  url = 'https://www.artble.com/imgs/c/d/1/98090/the_shipwreck_of_the_minotaur.jpg'\n",
        "  \n",
        "  response = requests.get(url)\n",
        "\n",
        "  file = open(\"the_shipwreck_of_the_minotaur.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_style_image(\"the_shipwreck_of_the_minotaur.jpg\")\n",
        "\n",
        "\n",
        "  #c'è anche per il content image\n",
        "  \n",
        "  url = 'https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg'\n",
        "  response = requests.get(url)\n",
        "  file = open(\"Tuebingen_Neckarfront.jpg\", \"wb\")\n",
        "  file.write(response.content)\n",
        "  file.close()\n",
        "\n",
        "  model.set_content_image(\"Tuebingen_Neckarfront.jpg\")\n",
        "  \n",
        "  training_image = tf.random.uniform(model.content_image.shape, minval=0, maxval=254, dtype=tf.dtypes.float32, seed=None, name=None)\n",
        "  \n",
        "  model.util.tensor_to_image(training_image).save(\"noise.jpg\")\n",
        "  \n",
        "\n",
        "  training_image_path=\"noise.jpg\"\n",
        "  model.set_training_image(training_image_path)\n",
        "  #model.set_training_image(tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'))\n",
        "  #posso anche cambiare i layers\n",
        "  content_layers = ['block4_conv2']\n",
        "  style_layers = ['block1_conv1','block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "  model.set_vgg_layers(style_layers, content_layers)\n",
        "\n",
        "\n",
        "  image=model_training_and_output(epochs,steps_per_epoch,model)\n",
        "\n",
        "\n",
        "file_name = 'paper_fig2_minotaur.png'\n",
        "model.util.tensor_to_image(image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqxUicSPUOP6"
      },
      "source": [
        "### Import and configure modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyftRTSMuwue"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "# Load compressed models from tensorflow_hub\n",
        "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc1OLbOWhPCO"
      },
      "source": [
        "import IPython.display as display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM6VEGrGLh62"
      },
      "source": [
        "def tensor_to_image(tensor):\n",
        "  tensor = tensor*255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0] == 1\n",
        "    tensor = tensor[0]\n",
        "  return PIL.Image.fromarray(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvCjfqXQW1Yz"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm1n78oRW8db"
      },
      "source": [
        "style_path = \"/content/sample_data/kakashi.jpg\"\n",
        "content_path= \"/content/gdrive/MyDrive/carlo.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeXebYusyHwC"
      },
      "source": [
        "Download images and choose a style image and a content image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqc0OJHwyFAk"
      },
      "source": [
        "#content_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')\n",
        "#style_path = tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE4Yt8nArTeR"
      },
      "source": [
        "## Visualize the input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klh6ObK2t_vH"
      },
      "source": [
        "Define a function to load an image and limit its maximum dimension to 512 pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TLljcwv5qZs"
      },
      "source": [
        "def load_img(path_to_img):\n",
        "  max_dim = 512\n",
        "  img = tf.io.read_file(path_to_img)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim / long_dim\n",
        "\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "\n",
        "  img = tf.image.resize(img, new_shape)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yAlRzJZrWM3"
      },
      "source": [
        "Create a simple function to display an image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBX-eNT8PAK_"
      },
      "source": [
        "def imshow(image, title=None):\n",
        "  if len(image.shape) > 3:\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "\n",
        "  plt.imshow(image)\n",
        "  if title:\n",
        "    plt.title(title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UWQmeEaiKkP"
      },
      "source": [
        "content_image = load_img(content_path)\n",
        "style_image = load_img(style_path)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(content_image, 'Content Image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(style_image, 'Style Image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMzChXSlKTA2"
      },
      "source": [
        "## Fast Style Transfer using TF-Hub\n",
        "\n",
        "This tutorial demonstrates the original style-transfer algorithm, which optimizes the image content to a particular style. Before getting into the details, let's see how the [TensorFlow Hub model](https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2) does this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYSLexgRKSh-"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
        "\n",
        "stylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\n",
        "tensor_to_image(stylized_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEwZ7FlwrjoZ"
      },
      "source": [
        "## Define content and style representations\n",
        "\n",
        "Use the intermediate layers of the model to get the *content* and *style* representations of the image. Starting from the network's input layer, the first few layer activations represent low-level features like edges and textures. As you step through the network, the final few layers represent higher-level features—object parts like *wheels* or *eyes*. In this case, you are using the VGG19 network architecture, a pretrained image classification network. These intermediate layers are necessary to define the representation of content and style from the images. For an input image, try to match the corresponding style and content target representations at these intermediate layers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP_7zrziuiJk"
      },
      "source": [
        "Load a [VGG19](https://keras.io/applications/#vgg19) and test run it on our image to ensure it's used correctly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMbzrr7BCTq0"
      },
      "source": [
        "x = tf.keras.applications.vgg19.preprocess_input(content_image*255)\n",
        "x = tf.image.resize(x, (224, 224))\n",
        "vgg = tf.keras.applications.VGG19(include_top=True, weights='imagenet')\n",
        "prediction_probabilities = vgg(x)\n",
        "prediction_probabilities.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_FyCm0dYnvl"
      },
      "source": [
        "predicted_top_5 = tf.keras.applications.vgg19.decode_predictions(prediction_probabilities.numpy())[0]\n",
        "[(class_name, prob) for (number, class_name, prob) in predicted_top_5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljpoYk-0f6HS"
      },
      "source": [
        "Now load a `VGG19` without the classification head, and list the layer names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh_AV6220ebD"
      },
      "source": [
        "vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "\n",
        "print()\n",
        "for layer in vgg.layers:\n",
        "  print(layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt-tASys0eJv"
      },
      "source": [
        "Choose intermediate layers from the network to represent the style and content of the image:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArfX_6iA0WAX"
      },
      "source": [
        "content_layers = ['block5_conv2'] \n",
        "\n",
        "style_layers = ['block1_conv1',\n",
        "                'block2_conv1',\n",
        "                'block3_conv1', \n",
        "                'block4_conv1', \n",
        "                'block5_conv1']\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers = len(style_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o4nSwuN0U3X"
      },
      "source": [
        "#### Intermediate layers for style and content\n",
        "\n",
        "So why do these intermediate outputs within our pretrained image classification network allow us to define style and content representations?\n",
        "\n",
        "At a high level, in order for a network to perform image classification (which this network has been trained to do), it must understand the image. This requires taking the raw image as input pixels and building an internal representation that converts the raw image pixels into a complex understanding of the features present within the image.\n",
        "\n",
        "This is also a reason why convolutional neural networks are able to generalize well: they’re able to capture the invariances and defining features within classes (e.g. cats vs. dogs) that are agnostic to background noise and other nuisances. Thus, somewhere between where the raw image is fed into the model and the output classification label, the model serves as a complex feature extractor. By accessing intermediate layers of the model, you're able to describe the content and style of input images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt3i3RRrJiOX"
      },
      "source": [
        "## Build the model \n",
        "\n",
        "The networks in `tf.keras.applications` are designed so you can easily extract the intermediate layer values using the Keras functional API.\n",
        "\n",
        "To define a model using the functional API, specify the inputs and outputs:\n",
        "\n",
        "`model = Model(inputs, outputs)`\n",
        "\n",
        "This following function builds a VGG19 model that returns a list of intermediate layer outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfec6MuMAbPx"
      },
      "source": [
        "def vgg_layers(layer_names):\n",
        "  \"\"\" Creates a vgg model that returns a list of intermediate output values.\"\"\"\n",
        "  # Load our model. Load pretrained VGG, trained on imagenet data\n",
        "  vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "  vgg.trainable = False\n",
        "  \n",
        "  outputs = [vgg.get_layer(name).output for name in layer_names]\n",
        "\n",
        "  model = tf.keras.Model([vgg.input], outputs)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbaIvZf5wWn_"
      },
      "source": [
        "And to create the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkyvPpBHSfVi"
      },
      "source": [
        "style_extractor = vgg_layers(style_layers)\n",
        "style_outputs = style_extractor(style_image*255)\n",
        "\n",
        "#Look at the statistics of each layer's output\n",
        "for name, output in zip(style_layers, style_outputs):\n",
        "  print(name)\n",
        "  print(\"  shape: \", output.numpy().shape)\n",
        "  print(\"  min: \", output.numpy().min())\n",
        "  print(\"  max: \", output.numpy().max())\n",
        "  print(\"  mean: \", output.numpy().mean())\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGUfttK9F8d5"
      },
      "source": [
        "## Calculate style\n",
        "\n",
        "The content of an image is represented by the values of the intermediate feature maps.\n",
        "\n",
        "It turns out, the style of an image can be described by the means and correlations across the different feature maps. Calculate a Gram matrix that includes this information by taking the outer product of the feature vector with itself at each location, and averaging that outer product over all locations. This Gram matrix can be calculated for a particular layer as:\n",
        "\n",
        "$$G^l_{cd} = \\frac{\\sum_{ij} F^l_{ijc}(x)F^l_{ijd}(x)}{IJ}$$\n",
        "\n",
        "This can be implemented concisely using the `tf.linalg.einsum` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAy1iGPdoEpZ"
      },
      "source": [
        "def gram_matrix(input_tensor):\n",
        "  result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
        "  input_shape = tf.shape(input_tensor)\n",
        "  num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
        "  return result/(num_locations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXIUX6czZABh"
      },
      "source": [
        "## Extract style and content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HGHvwlJ1nkn"
      },
      "source": [
        "Build a model that returns the style and content tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr6QALY-I1ja"
      },
      "source": [
        "class StyleContentModel(tf.keras.models.Model):\n",
        "  def __init__(self, style_layers, content_layers):\n",
        "    super(StyleContentModel, self).__init__()\n",
        "    self.vgg =  vgg_layers(style_layers + content_layers)\n",
        "    self.style_layers = style_layers\n",
        "    self.content_layers = content_layers\n",
        "    self.num_style_layers = len(style_layers)\n",
        "    self.vgg.trainable = False\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"Expects float input in [0,1]\"\n",
        "    inputs = inputs*255.0\n",
        "    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
        "    outputs = self.vgg(preprocessed_input)\n",
        "    style_outputs, content_outputs = (outputs[:self.num_style_layers], \n",
        "                                      outputs[self.num_style_layers:])\n",
        "\n",
        "    style_outputs = [gram_matrix(style_output)\n",
        "                     for style_output in style_outputs]\n",
        "\n",
        "    content_dict = {content_name:value \n",
        "                    for content_name, value \n",
        "                    in zip(self.content_layers, content_outputs)}\n",
        "\n",
        "    style_dict = {style_name:value\n",
        "                  for style_name, value\n",
        "                  in zip(self.style_layers, style_outputs)}\n",
        "    \n",
        "    return {'content':content_dict, 'style':style_dict}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuj1o33t1edl"
      },
      "source": [
        "When called on an image, this model returns the gram matrix (style) of the `style_layers` and content of the `content_layers`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkjO-DoNDU0A"
      },
      "source": [
        "extractor = StyleContentModel(style_layers, content_layers)\n",
        "\n",
        "results = extractor(tf.constant(content_image))\n",
        "\n",
        "print('Styles:')\n",
        "for name, output in sorted(results['style'].items()):\n",
        "  print(\"  \", name)\n",
        "  print(\"    shape: \", output.numpy().shape)\n",
        "  print(\"    min: \", output.numpy().min())\n",
        "  print(\"    max: \", output.numpy().max())\n",
        "  print(\"    mean: \", output.numpy().mean())\n",
        "  print()\n",
        "\n",
        "print(\"Contents:\")\n",
        "for name, output in sorted(results['content'].items()):\n",
        "  print(\"  \", name)\n",
        "  print(\"    shape: \", output.numpy().shape)\n",
        "  print(\"    min: \", output.numpy().min())\n",
        "  print(\"    max: \", output.numpy().max())\n",
        "  print(\"    mean: \", output.numpy().mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9r8Lyjb_m0u"
      },
      "source": [
        "## Run gradient descent\n",
        "\n",
        "With this style and content extractor, you can now implement the style transfer algorithm. Do this by calculating the mean square error for your image's output relative to each target, then take the weighted sum of these losses.\n",
        "\n",
        "Set your style and content target values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgkNOnGUFcKa"
      },
      "source": [
        "style_targets = extractor(style_image)['style']\n",
        "content_targets = extractor(content_image)['content']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNPrpl-e_w9A"
      },
      "source": [
        "Define a `tf.Variable` to contain the image to optimize. To make this quick, initialize it with the content image (the `tf.Variable` must be the same shape as the content image):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0vKxF8ZO6G8"
      },
      "source": [
        "image = tf.Variable(content_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6L8ojmn_6rH"
      },
      "source": [
        "Since this is a float image, define a function to keep the pixel values between 0 and 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdgpTJwL_vE2"
      },
      "source": [
        "def clip_0_1(image):\n",
        "  return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBU5RFpcAo7W"
      },
      "source": [
        "Create an optimizer. The paper recommends LBFGS, but `Adam` works okay, too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4XZjqUk_5Eu"
      },
      "source": [
        "opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As-evbBiA2qT"
      },
      "source": [
        "To optimize this, use a weighted combination of the two losses to get the total loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt4pxarvA4I4"
      },
      "source": [
        "style_weight=10\n",
        "content_weight=1e4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ggx2Na8oROH"
      },
      "source": [
        "def style_content_loss(outputs):\n",
        "    style_outputs = outputs['style']\n",
        "    content_outputs = outputs['content']\n",
        "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) \n",
        "                           for name in style_outputs.keys()])\n",
        "    style_loss *= style_weight / num_style_layers\n",
        "\n",
        "    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2) \n",
        "                             for name in content_outputs.keys()])\n",
        "    content_loss *= content_weight / num_content_layers\n",
        "    loss = style_loss + content_loss\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbF2WnP9BI5M"
      },
      "source": [
        "Use `tf.GradientTape` to update the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t0umkajFIuh"
      },
      "source": [
        "@tf.function()\n",
        "def train_step(image):\n",
        "  with tf.GradientTape() as tape:\n",
        "    outputs = extractor(image)\n",
        "    loss = style_content_loss(outputs)\n",
        "\n",
        "  grad = tape.gradient(loss, image)\n",
        "  opt.apply_gradients([(grad, image)])\n",
        "  image.assign(clip_0_1(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FHMJq4UBRIQ"
      },
      "source": [
        "Now run a few steps to test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y542mxi-O2a2"
      },
      "source": [
        "train_step(image)\n",
        "train_step(image)\n",
        "train_step(image)\n",
        "tensor_to_image(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNzE-mTbBVgY"
      },
      "source": [
        "Since it's working, perform a longer optimization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQW1tXYoLbUS"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "epochs = 10\n",
        "steps_per_epoch = 100\n",
        "\n",
        "step = 0\n",
        "for n in range(epochs):\n",
        "  for m in range(steps_per_epoch):\n",
        "    step += 1\n",
        "    train_step(image)\n",
        "    print(\".\", end='')\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(tensor_to_image(image))\n",
        "  print(\"Train step: {}\".format(step))\n",
        "  \n",
        "end = time.time()\n",
        "print(\"Total time: {:.1f}\".format(end-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWVB3anJMY2v"
      },
      "source": [
        "## Total variation loss\n",
        "\n",
        "One downside to this basic implementation is that it produces a lot of high frequency artifacts. Decrease these using an explicit regularization term on the high frequency components of the image. In style transfer, this is often called the *total variation loss*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7szUUybCQMB3"
      },
      "source": [
        "def high_pass_x_y(image):\n",
        "  x_var = image[:,:,1:,:] - image[:,:,:-1,:]\n",
        "  y_var = image[:,1:,:,:] - image[:,:-1,:,:]\n",
        "\n",
        "  return x_var, y_var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atc2oL29PXu_"
      },
      "source": [
        "x_deltas, y_deltas = high_pass_x_y(content_image)\n",
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.subplot(2,2,1)\n",
        "imshow(clip_0_1(2*y_deltas+0.5), \"Horizontal Deltas: Original\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "imshow(clip_0_1(2*x_deltas+0.5), \"Vertical Deltas: Original\")\n",
        "\n",
        "x_deltas, y_deltas = high_pass_x_y(image)\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "imshow(clip_0_1(2*y_deltas+0.5), \"Horizontal Deltas: Styled\")\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "imshow(clip_0_1(2*x_deltas+0.5), \"Vertical Deltas: Styled\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqHElVgBkgkz"
      },
      "source": [
        "This shows how the high frequency components have increased.\n",
        "\n",
        "Also, this high frequency component is basically an edge-detector. You can get similar output from the Sobel edge detector, for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyvqCiywiUfL"
      },
      "source": [
        "plt.figure(figsize=(14,10))\n",
        "\n",
        "sobel = tf.image.sobel_edges(content_image)\n",
        "plt.subplot(1,2,1)\n",
        "imshow(clip_0_1(sobel[...,0]/4+0.5), \"Horizontal Sobel-edges\")\n",
        "plt.subplot(1,2,2)\n",
        "imshow(clip_0_1(sobel[...,1]/4+0.5), \"Vertical Sobel-edges\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv5bKlSDnPP7"
      },
      "source": [
        "The regularization loss associated with this is the sum of the squares of the values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-92lXMIYPn"
      },
      "source": [
        "def total_variation_loss(image):\n",
        "  x_deltas, y_deltas = high_pass_x_y(image)\n",
        "  return tf.reduce_sum(tf.abs(x_deltas)) + tf.reduce_sum(tf.abs(y_deltas))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4OYBUX2KQ25"
      },
      "source": [
        "total_variation_loss(image).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu2hJ8zOKMc1"
      },
      "source": [
        "That demonstrated what it does. But there's no need to implement it yourself, TensorFlow includes a standard implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQjWW04NKLfJ"
      },
      "source": [
        "tf.image.total_variation(image).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTessd-DCdcC"
      },
      "source": [
        "## Re-run the optimization\n",
        "\n",
        "Choose a weight for the `total_variation_loss`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGeRLD4GoAd4"
      },
      "source": [
        "total_variation_weight=30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG1-T4kJsoAv"
      },
      "source": [
        "Now include it in the `train_step` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzmfcyyYUyWq"
      },
      "source": [
        "@tf.function()\n",
        "def train_step(image):\n",
        "  with tf.GradientTape() as tape:\n",
        "    outputs = extractor(image)\n",
        "    loss = style_content_loss(outputs)\n",
        "    loss += total_variation_weight*tf.image.total_variation(image)\n",
        "\n",
        "  grad = tape.gradient(loss, image)\n",
        "  opt.apply_gradients([(grad, image)])\n",
        "  image.assign(clip_0_1(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcLWBQChsutQ"
      },
      "source": [
        "Reinitialize the optimization variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-dPRr8BqexB"
      },
      "source": [
        "image = tf.Variable(content_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEflRstmtGBu"
      },
      "source": [
        "And run the optimization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3Cc3bLtoOWy"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "epochs = 30\n",
        "steps_per_epoch = 100\n",
        "\n",
        "step = 0\n",
        "for n in range(epochs):\n",
        "  for m in range(steps_per_epoch):\n",
        "    step += 1\n",
        "    train_step(image)\n",
        "    print(\".\", end='')\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(tensor_to_image(image))\n",
        "  print(\"Train step: {}\".format(step))\n",
        "\n",
        "end = time.time()\n",
        "print(\"Total time: {:.1f}\".format(end-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKox7K46tKxy"
      },
      "source": [
        "Finally, save the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSH6OpyyQn7w"
      },
      "source": [
        "file_name = 'Carllok.png'\n",
        "tensor_to_image(stylized_image).save(file_name)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNlwRXagxQZk"
      },
      "source": [
        "## Learn more\n",
        "\n",
        "This tutorial demonstrates the original style-transfer algorithm. For a simple application of style transfer check out this [tutorial](https://www.tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization) to learn more about how to use the arbitrary image style transfer model from [TensorFlow Hub](https://tfhub.dev)."
      ]
    }
  ]
}